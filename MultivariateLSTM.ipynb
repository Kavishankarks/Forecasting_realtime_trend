{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateLSTM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNjZnKTEgg0PRkgqL+cWkZj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavishankarks/Forecasting_realtime_trend/blob/main/MultivariateLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSAXN8MlNFGs"
      },
      "source": [
        "!pip install pytrends\n",
        "import plotly.express as px # to plot the time series plot\n",
        "from sklearn import metrics # for the evaluation\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from pandas import DataFrame\n",
        "from pytrends.request import TrendReq\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KepKi5eINO9V"
      },
      "source": [
        "# keywords=['deep learning','machine', 'python', 'network', 'image', 'ai', 'neural','reinforcement','google']\n",
        "keywords=['pes','University','vaccine','pfizer','covid','appointment', 'astrazeneca','covishield','moderna']\n",
        "dfk=DataFrame(keywords,columns=['Keywords'])\n",
        "dfk.reset_index(drop=True, inplace=True)\n",
        "dfk.to_csv('keywords.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUX5BQxyNX4R"
      },
      "source": [
        "def genData(date):\n",
        "  from pytrends.request import TrendReq\n",
        "  import pandas as pd\n",
        "  import time\n",
        "  startTime = time.time()\n",
        "  pytrend = TrendReq(hl='en-GB', tz=360)\n",
        "\n",
        "  colnames = [\"keywords\"]\n",
        "  df = pd.read_csv(\"keywords.csv\", names=colnames)\n",
        "  df2 = df[\"keywords\"].values.tolist()\n",
        "  df2.remove(\"Keywords\")\n",
        "\n",
        "  dataset = []\n",
        "\n",
        "  for x in range(0,len(df2)):\n",
        "      keywords = [df2[x]]\n",
        "      pytrend.build_payload(\n",
        "      kw_list=keywords,\n",
        "      cat=0,\n",
        "      timeframe=date,geo='GB')\n",
        "      data = pytrend.interest_over_time()\n",
        "      if not data.empty:\n",
        "            data = data.drop(labels=['isPartial'],axis='columns')\n",
        "            dataset.append(data)\n",
        "\n",
        "  result = pd.concat(dataset, axis=1)\n",
        "  result.to_csv('trends.csv')\n",
        "\n",
        "  executionTime = (time.time() - startTime)\n",
        "  print('Execution time in sec.: ' + str(executionTime))\n",
        "genData('2004-01-01 2021-10-10')\n",
        "data=pd.read_csv('trends.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnD_aMIhNmA6"
      },
      "source": [
        "data=pd.read_csv('trends.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pm6ASZQQC7e"
      },
      "source": [
        "res=['hel']\n",
        "a='pes university'\n",
        "a=a.split()\n",
        "for i in a:\n",
        "  res.insert(0,i)\n",
        "# res.extend(a)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTZX9aewNafg"
      },
      "source": [
        "def custom_ts_multi_data_prep(dataset, target, start, end, window, horizon):\n",
        "    X = []\n",
        "    y = []\n",
        "    start = start + window\n",
        "    if end is None:\n",
        "        end = len(dataset) - horizon\n",
        "    for i in range(start, end):\n",
        "        indices = range(i-window, i)\n",
        "        X.append(dataset[indices])\n",
        "        indicey = range(i+1, i+1+horizon)\n",
        "        y.append(target[indicey])\n",
        "    return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgXOJgQ4Nszc"
      },
      "source": [
        "a=[]\n",
        "for i in data.columns:\n",
        "    a.append(i)\n",
        "print(a)\n",
        "for i in data.select_dtypes('object').columns:\n",
        "    le = LabelEncoder().fit(data[i])\n",
        "    data[i] = le.transform(data[i])                         \n",
        "name=a[1]\n",
        "X_scaler = MinMaxScaler()\n",
        "Y_scaler = MinMaxScaler()\n",
        "X_data = X_scaler.fit_transform(data[a])\n",
        "Y_data = Y_scaler.fit_transform(data[[name]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJtXJiHQTDus"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElSuB_XmTWhB"
      },
      "source": [
        "validate = data[a[1]].tail(10)\n",
        "# data.drop(data.tail(10).index,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lEdYKRvVWqX"
      },
      "source": [
        "hist_window = 3\n",
        "horizon = 7\n",
        "TRAIN_SPLIT = 150\n",
        "x_train, y_train = custom_ts_multi_data_prep(X_data, Y_data, 0, TRAIN_SPLIT, hist_window, horizon)\n",
        "x_vali, y_vali = custom_ts_multi_data_prep(X_data, Y_data, TRAIN_SPLIT, None, hist_window, horizon)\n",
        "print ('Multiple window of past history\\n')\n",
        "print(x_train[0])\n",
        "print ('\\n Target horizon\\n')\n",
        "print (y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hM1-VwgN2QQ"
      },
      "source": [
        "# Prepare the training data and validation data using \n",
        "# the TensorFlow data function, which faster and efficient way to feed data for training.\n",
        "batch_size = 256\n",
        "buffer_size = 150\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
        "val_data = val_data.batch(batch_size).repeat() \n",
        "\n",
        "# Build and compile the model\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200, return_sequences=True), \n",
        "                                input_shape=x_train.shape[-2:]),\n",
        "     tf.keras.layers.Dense(20, activation='tanh'),\n",
        "     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "     tf.keras.layers.Dense(20, activation='tanh'),\n",
        "     tf.keras.layers.Dense(20, activation='tanh'),\n",
        "     tf.keras.layers.Dropout(0.25),\n",
        "     tf.keras.layers.Dense(units=horizon),\n",
        " ])\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "lstm_model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDR9HCizN53S"
      },
      "source": [
        "# Configure the model and start training with early stopping and checkpoint.\n",
        "# Early stopping stops training when monitored loss starts increasing above the patience,\n",
        "# and checkpoint saves the model weight as it reaches the minimum loss.\n",
        "model_path = 'Bidirectional_LSTM_Multivariate.h5'\n",
        "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
        "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
        "callbacks=[early_stopings,checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Hoe6U6N9sP"
      },
      "source": [
        "history = lstm_model.fit(train_data,epochs=10,steps_per_epoch=5,validation_data=val_data,validation_steps=50,verbose=1,callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkQjoE1IOB4S"
      },
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvCyfiFwPS7A"
      },
      "source": [
        "data_val = X_scaler.fit_transform(data[a].tail(10))\n",
        "val_rescaled = data_val.reshape(1, data_val.shape[0], data_val.shape[1])\n",
        "pred = lstm_model.predict(val_rescaled)\n",
        "pred_Inverse = Y_scaler.inverse_transform(pred)\n",
        "pred_Inverse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZPyyyLP2z0"
      },
      "source": [
        "name=a[1]\n",
        "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
        "  def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "  print('Evaluation metric results:-')\n",
        "  print(len(y_true),len(y_pred))\n",
        "  print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
        "  print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
        "  print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
        "  print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
        "  print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')\n",
        "timeseries_evaluation_metrics_func(validate[:7],pred_Inverse[0])\n",
        "print(len(pred_Inverse[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0izZePJRMrY"
      },
      "source": [
        "name=a[1]\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(list(validate))\n",
        "plt.plot(list(pred_Inverse[0]))\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.ylabel(name)\n",
        "plt.legend(('Actual','predicted'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMDGswWcSJQM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkq07_SQFEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}